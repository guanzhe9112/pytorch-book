{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B02ZgVpKUBg"
      },
      "source": [
        "# 第三章 PyTorch基础：Tensor和Autograd\n",
        "\n",
        "## 3.1 Tensor\n",
        "\n",
        "Tensor，又名张量，读者可能对这个名词似曾相识，因它不仅在PyTorch中出现过，它也是Theano、TensorFlow、\n",
        "Torch和MxNet中重要的数据结构。关于张量的本质不乏深度的剖析，但从工程角度来讲，可简单地认为它就是一个数组，且支持高效的科学计算。它可以是一个数（标量）、一维数组（向量）、二维数组（矩阵）和更高维的数组（高阶数据）。Tensor和Numpy的ndarrays类似，但PyTorch的tensor支持GPU加速。\n",
        "\n",
        "本节将系统讲解tensor的使用，力求面面俱到，但不会涉及每个函数。对于更多函数及其用法，读者可通过在IPython/Notebook中使用函数名加`?`查看帮助文档，或查阅PyTorch官方文档[^1]。\n",
        "\n",
        "[^1]: http://docs.pytorch.org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3lY68GscKUBk",
        "outputId": "7518173d-9136-4207-901a-1630f302efda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Let's begin\n",
        "from __future__ import print_function\n",
        "import torch  as t\n",
        "t.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_QGy90xKUBm"
      },
      "source": [
        "###  3.1.1 基础操作\n",
        "\n",
        "学习过Numpy的读者会对本节内容感到非常熟悉，因tensor的接口有意设计成与Numpy类似，以方便用户使用。但不熟悉Numpy也没关系，本节内容并不要求先掌握Numpy。\n",
        "\n",
        "从接口的角度来讲，对tensor的操作可分为两类：\n",
        "\n",
        "1. `torch.function`，如`torch.save`等。\n",
        "2. 另一类是`tensor.function`，如`tensor.view`等。\n",
        "\n",
        "为方便使用，对tensor的大部分操作同时支持这两类接口，在本书中不做具体区分，如`torch.sum (torch.sum(a, b))`与`tensor.sum (a.sum(b))`功能等价。\n",
        "\n",
        "而从存储的角度来讲，对tensor的操作又可分为两类：\n",
        "\n",
        "1. 不会修改自身的数据，如 `a.add(b)`， 加法的结果会返回一个新的tensor。\n",
        "2. 会修改自身的数据，如 `a.add_(b)`， 加法的结果仍存储在a中，a被修改了。\n",
        "\n",
        "函数名以`_`结尾的都是inplace方式, 即会修改调用者自己的数据，在实际应用中需加以区分。\n",
        "\n",
        "#### 创建Tensor\n",
        "\n",
        "在PyTorch中新建tensor的方法有很多，具体如表3-1所示。\n",
        "\n",
        "表3-1: 常见新建tensor的方法\n",
        "\n",
        "|函数|功能|\n",
        "|:---:|:---:|\n",
        "|Tensor(\\*sizes)|基础构造函数|\n",
        "|tensor(data,)|类似np.array的构造函数|\n",
        "|ones(\\*sizes)|全1Tensor|\n",
        "|zeros(\\*sizes)|全0Tensor|\n",
        "|eye(\\*sizes)|对角线为1，其他为0|\n",
        "|arange(s,e,step|从s到e，步长为step|\n",
        "|linspace(s,e,steps)|从s到e，均匀切分成steps份|\n",
        "|rand/randn(\\*sizes)|均匀/标准分布|\n",
        "|normal(mean,std)/uniform(from,to)|正态分布/均匀分布|\n",
        "|randperm(m)|随机排列|\n",
        "\n",
        "这些创建方法都可以在创建的时候指定数据类型dtype和存放device(cpu/gpu).\n",
        "\n",
        "\n",
        "其中使用`Tensor`函数新建tensor是最复杂多变的方式，它既可以接收一个list，并根据list的数据新建tensor，也能根据指定的形状新建tensor，还能传入其他的tensor，下面举几个例子。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MEzQ7TuwKUBn",
        "outputId": "cbe0dbf0-997d-4891-e395-e413567a026e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.8976e-23,  3.0791e-41,  3.7835e-44],\n",
              "        [ 0.0000e+00,         nan,  3.0791e-41]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 指定tensor的形状\n",
        "a = t.Tensor(2, 3)\n",
        "a # 数值取决于内存空间的状态，print时候可能overflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KWBt7onOKUBo",
        "outputId": "d50ac9bc-eea6-4aa5-d13f-84ac091a969b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 用list的数据创建tensor\n",
        "b = t.Tensor([[1,2,3],[4,5,6]])\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CSRqkThPKUBp",
        "outputId": "9e29233e-6fbd-4dc9-d8ed-6acede298a13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "b.tolist() # 把tensor转为list\n",
        "b.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdMrlVSnKUBp"
      },
      "source": [
        "`tensor.size()`返回`torch.Size`对象，它是tuple的子类，但其使用方式与tuple略有区别"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": true,
        "id": "w68lti6nKUBq",
        "outputId": "88eb4505-cd2a-4a96-b017-3a825fd76651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "b_size = b.size()\n",
        "b_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FNLet87oKUBq",
        "outputId": "7ffb1f04-27e9-4a96-92f4-6b50e565134f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "b.numel() # b中元素总个数，2*3，等价于b.nelement()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "scrolled": true,
        "id": "siHBoaW2KUBr",
        "outputId": "dea9a564-ce5b-4745-c6e1-cb29896cf59f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-6.4805073023352e+28"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# 创建一个和b形状一样的tensor\n",
        "c = t.Tensor(b_size)\n",
        "# 创建一个元素为2和3的tensor\n",
        "d = t.Tensor((2, 3))\n",
        "c, d\n",
        "c[0][0].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmDXfyS5KUBr"
      },
      "source": [
        "除了`tensor.size()`，还可以利用`tensor.shape`直接查看tensor的形状，`tensor.shape`等价于`tensor.size()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZrsLcFgIKUBs",
        "outputId": "9169a037-8ea2-48a4-bc27-4a70be2817d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "c.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH9M8N6JKUBs"
      },
      "source": [
        "需要注意的是，`t.Tensor(*sizes)`创建tensor时，系统不会马上分配空间，只是会计算剩余的内存是否足够使用，使用到tensor时才会分配，而其它操作都是在创建完tensor之后马上进行空间分配。其它常用的创建tensor的方法举例如下。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "scrolled": true,
        "id": "254L12ahKUBs",
        "outputId": "396562f6-8e26-4ac0-cf91-df319ad36eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "t.ones(2, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "k42ZZhCZKUBt",
        "outputId": "065db935-2c60-4aee-d9a9-7b1a51a427bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "t.zeros(2, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ECtRd4jZKUBt",
        "outputId": "4f963af7-f4f9-4325-b99c-b6232ddef172",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "t.arange(1, 6, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WVFNcDxsKUBu",
        "outputId": "8f459806-065f-4bf1-c383-bf04dd5310d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.,  4.,  7., 10.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "t.linspace(1, 10, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Vz4JFrAIKUBu",
        "outputId": "1c1daac1-20f4-42a8-d663-0091da9c0673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1343,  1.1452,  1.0841],\n",
              "        [-2.3269, -2.9313, -0.2127]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "t.randn(2, 3, device=t.device('cpu'))\n",
        "t.randn(2, 3, device=t.device('cuda'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "scrolled": true,
        "id": "PcX3rM0UKUBu",
        "outputId": "9f40dded-091e-4848-d2a0-7634741588dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 4, 2, 3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "t.randperm(5) # 长度为5的随机排列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "scrolled": true,
        "id": "nnrQMoWoKUBu",
        "outputId": "c0cad6a4-9722-4861-905a-fa7db3d9e147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0],\n",
              "        [0, 1, 0]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "t.eye(2, 3, dtype=t.int) # 对角线为1, 不要求行列数一致"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOa5qQh_KUBv"
      },
      "source": [
        "`torch.tensor`是在0.4版本新增加的一个新版本的创建tensor方法，使用的方法，和参数几乎和`np.array`完全一致"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZEiYRE0WKUBv",
        "outputId": "7ae931e5-7ee9-4636-8a1d-dbbefc5644b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scalar: tensor(3.1416), shape of sclar: torch.Size([])\n"
          ]
        }
      ],
      "source": [
        "scalar = t.tensor(3.14159) \n",
        "print('scalar: %s, shape of sclar: %s' %(scalar, scalar.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mLv3OJgqKUBv",
        "outputId": "d53673ed-2993-4bcd-c160-71db215c7ca3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector: tensor([1, 2]), shape of vector: torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "vector = t.tensor([1, 2])\n",
        "print('vector: %s, shape of vector: %s' %(vector, vector.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "k-RLJn1FKUBw",
        "outputId": "99ce8eff-f33d-4efc-dece-54229f156085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.4804e+28,  3.0791e-41]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "tensor = t.Tensor(1,2) # 注意和t.tensor([1, 2])的区别\n",
        "tensor.shape\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "aJ2zrH8UKUBw",
        "outputId": "c1048b1e-e247-425e-a0f6-2cec51eed0e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1000, 1.2000],\n",
              "         [2.2000, 3.1000],\n",
              "         [4.9000, 5.2000]]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "matrix = t.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
        "matrix,matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hFZaxIAbKUBw",
        "outputId": "2b759d38-e777-4c61-b840-e06348aee8c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1111, 0.2222, 0.3333]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "t.tensor([[0.11111, 0.222222, 0.3333333]],\n",
        "                     dtype=t.float64,\n",
        "                     device=t.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "evoiIu-tKUBw",
        "outputId": "508bc071-3b66-4a7f-d2c2-c9cebf421bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "empty_tensor = t.tensor([])\n",
        "empty_tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEKMatrDKUBx"
      },
      "source": [
        "#### 常用Tensor操作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkHKNnBgKUBx"
      },
      "source": [
        "通过`tensor.view`方法可以调整tensor的形状，但必须保证调整前后元素总数一致。`view`不会修改自身的数据，返回的新tensor与源tensor共享内存，也即更改其中的一个，另外一个也会跟着改变。在实际应用中可能经常需要添加或减少某一维度，这时候`squeeze`和`unsqueeze`两个函数就派上用场了。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "scrolled": true,
        "id": "ikWf_ikCKUBx",
        "outputId": "e890f26a-56b7-4c61-d7c1-17855a5426ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "a = t.arange(0, 6)\n",
        "a.view(2, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "scrolled": true,
        "id": "6PI3L9lUKUBx",
        "outputId": "9bd09222-0fb3-4b58-cba4-bdced5d38620",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "b = a.view(-1, 3) # 当某一维为-1的时候，会自动计算它的大小\n",
        "b.shape\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6MohAIUuKUBx",
        "outputId": "45a1271f-6064-4f7a-f3ff-e9f6d503bec0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "b.unsqueeze(1) # 注意形状，在第1维（下标从0开始）上增加“１” \n",
        "#等价于 b[:,None]\n",
        "b[:, None].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "q_opfGU4KUBy",
        "outputId": "c0b76300-370f-47ac-cb5c-6b81002b3d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 1, 2]],\n",
              "\n",
              "        [[3, 4, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "b.unsqueeze(-2) # -2表示倒数第二个维度"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "scrolled": true,
        "id": "WlPWpHtBKUBy",
        "outputId": "6d006ee8-1200-4928-af4e-42947d102f25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0, 1, 2],\n",
              "          [3, 4, 5]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "c = b.view(1, 1, 1, 2, 3)\n",
        "c.squeeze(0) # 压缩第0维的“１”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "AiQFY1-1KUBy",
        "outputId": "521a5383-6fd2-4152-d3af-cf694a5dc8be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "c.squeeze() # 把所有维度为“1”的压缩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "MaKKKlWYKUBy",
        "outputId": "8cc2dde2-c406-4805-d41a-3a654a8e8eef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0, 100,   2],\n",
              "        [  3,   4,   5]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "a[1] = 100\n",
        "b # a修改，b作为view之后的，也会跟着修改"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxdBO2wCKUBz"
      },
      "source": [
        "`resize`是另一种可用来调整`size`的方法，但与`view`不同，它可以修改tensor的大小。如果新大小超过了原大小，会自动分配新的内存空间，而如果新大小小于原大小，则之前的数据依旧会被保存，看一个例子。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "HXLRgiQ3KUBz",
        "outputId": "27c419f3-ad55-4606-a36c-930bfe0a7380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 3, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "b.resize_(1, 3)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "scrolled": true,
        "id": "LQp7-_azKUBz"
      },
      "outputs": [],
      "source": [
        "b.resize_(3, 3) # 旧的数据依旧保存着，多出的大小会分配新空间\n",
        "b.resize_?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5emyaMtKUBz"
      },
      "source": [
        "#### 索引操作\n",
        "\n",
        "Tensor支持与numpy.ndarray类似的索引操作，语法上也类似，下面通过一些例子，讲解常用的索引操作。如无特殊说明，索引出来的结果与原tensor共享内存，也即修改一个，另一个会跟着修改。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "UK7A-hTPKUBz",
        "outputId": "50768a2c-f7ed-4000-aa05-086004f6a89b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.1840, -0.9544, -1.5772,  0.7515],\n",
              "        [-1.0171, -1.1734, -1.8251,  0.7037],\n",
              "        [-0.0032, -0.4664, -1.0055,  1.4844]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "a = t.randn(3, 4)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nb4GMyodKUBz",
        "outputId": "8229ce3a-3279-4192-815c-3f7760d3804c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1.1741,  1.4335, -0.8156,  0.7622])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[0] # 第0行(下标从0开始)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1GJTUC3KUB0",
        "outputId": "3065b4aa-b29e-4f42-9a70-32000834735c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1.1741, -0.6334, -0.6551])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[:, 0] # 第0列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa6bMNV4KUB0",
        "outputId": "939d220b-4902-43b3-e7e5-9a0c092282c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.8156)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[0][2] # 第0行第2个元素，等价于a[0, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALBP7S5hKUB0",
        "outputId": "bd9eaaa3-bdc8-42be-9d6b-d2ac97abb001"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.7622)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[0, -1] # 第0行最后一个元素"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LwVUQ09ZKUB0",
        "outputId": "ca7a643c-df49-49be-ff71-1cbd4215508c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.1741,  1.4335, -0.8156,  0.7622],\n",
              "        [-0.6334, -1.4628, -0.7428,  0.0410]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[:2] # 前两行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5XOBRw0KUB0",
        "outputId": "206009f8-7f81-4128-e40d-e3cf325aff82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.1741,  1.4335],\n",
              "        [-0.6334, -1.4628]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[:2, 0:2] # 前两行，第0,1列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HILmj6r8KUB1",
        "outputId": "36f74e2f-d8ad-4d10-db15-c361e8296597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.1741, 1.4335]])\n",
            "tensor([1.1741, 1.4335])\n"
          ]
        }
      ],
      "source": [
        "print(a[0:1, :2]) # 第0行，前两列 \n",
        "print(a[0, :2]) # 注意两者的区别：形状不同"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "1OwVd7TsKUB1",
        "outputId": "d393606c-64e0-4f89-a601-ebcca2ce3d36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# None类似于np.newaxis, 为a新增了一个轴\n",
        "# 等价于a.view(1, a.shape[0], a.shape[1])\n",
        "a[None].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja1M0A7kKUB1",
        "outputId": "58f304fc-10e8-4f75-bebe-88cf8d35b4fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 4])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[None].shape # 等价于a[None,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "7B8W4YClKUB1",
        "outputId": "9e05db9d-2f75-4b66-bb76-df4f27cfecd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "a[:,None,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2TaGjryKUB1",
        "outputId": "a515b5c5-dc9a-4700-cec2-654e336469c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 4, 1, 1])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[:,None,:,None,None].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2A6vIgE4KUB2",
        "outputId": "832578dc-1180-4248-f98d-3e804a6a6b4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "a > 1 # 返回一个ByteTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "LeBNqeUHKUB2",
        "outputId": "334926be-4836-445a-ffcb-2f8c338d04a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1840, 1.4844])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "a[a>1] # 等价于a.masked_select(a>1)\n",
        "# 选择结果与原tensor不共享内存空间"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "scrolled": true,
        "id": "xAb6xJAQKUB2",
        "outputId": "b46ae1e6-3033-46a5-9a16-d3bcad34a448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.1840, -0.9544, -1.5772,  0.7515],\n",
              "        [-1.0171, -1.1734, -1.8251,  0.7037]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "a[t.LongTensor([0,1])] # 第0行和第1行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PWPm5aqKUB2"
      },
      "source": [
        "其它常用的选择函数如表3-2所示。\n",
        "\n",
        "表3-2常用的选择函数\n",
        "\n",
        "函数|功能|\n",
        ":---:|:---:|\n",
        "index_select(input, dim, index)|在指定维度dim上选取，比如选取某些行、某些列\n",
        "masked_select(input, mask)|例子如上，a[a>0]，使用ByteTensor进行选取\n",
        "non_zero(input)|非0元素的下标\n",
        "gather(input, dim, index)|根据index，在dim维度上选取数据，输出的size与index一样\n",
        "\n",
        "\n",
        "`gather`是一个比较复杂的操作，对一个2维tensor，输出的每个元素如下：\n",
        "\n",
        "```python\n",
        "out[i][j] = input[index[i][j]][j]  # dim=0\n",
        "out[i][j] = input[i][index[i][j]]  # dim=1\n",
        "```\n",
        "三维tensor的`gather`操作同理，下面举几个例子。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_8w1UV1vKUB2",
        "outputId": "5bab8bee-08d0-41e3-e483-b4551df18794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "a = t.arange(0, 16).view(4, 4)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "PJby3-DPKUB3",
        "outputId": "bc380dce-14b9-46cd-8a49-4f859bff446b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  5, 10, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# 选取对角线的元素\n",
        "index = t.LongTensor([[0,1,2,3]])\n",
        "a.gather(0, index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "CL4ELHvfKUB3",
        "outputId": "b8cb1708-92fa-44bc-ad06-85d346418862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# 选取反对角线上的元素\n",
        "index = t.LongTensor([[3,2,1,0]]).t()\n",
        "a.gather(1, index)\n",
        "index.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I502GNAmKUB3",
        "outputId": "f08219dd-4c95-4b1b-bd4a-b6a440dea866"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[12,  9,  6,  3]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 选取反对角线上的元素，注意与上面的不同\n",
        "index = t.LongTensor([[3,2,1,0]])\n",
        "a.gather(0, index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "sCS_T7WVKUB3",
        "outputId": "10475418-b0bf-411a-c996-955e6fd5cb12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  3],\n",
              "        [ 5,  6],\n",
              "        [10,  9],\n",
              "        [15, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# 选取两个对角线上的元素\n",
        "index = t.LongTensor([[0,1,2,3],[3,2,1,0]]).t()\n",
        "b = a.gather(1, index)\n",
        "b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ7u16OaKUB4"
      },
      "source": [
        "与`gather`相对应的逆操作是`scatter_`，`gather`把数据从input中按index取出，而`scatter_`是把取出的数据再放回去。注意`scatter_`函数是inplace操作。\n",
        "\n",
        "```python\n",
        "out = input.gather(dim, index)\n",
        "-->近似逆操作\n",
        "out = Tensor()\n",
        "out.scatter_(dim, index)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "riVDcdRCKUB4",
        "outputId": "1aa45818-bb6c-43a4-f353-239ad65f1efc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  0.,  0.,  3.],\n",
              "        [ 0.,  5.,  6.,  0.],\n",
              "        [ 0.,  9., 10.,  0.],\n",
              "        [12.,  0.,  0., 15.]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 把两个对角线元素放回去到指定位置\n",
        "c = t.zeros(4,4)\n",
        "c.scatter_(1, index, b.float())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCwIWUXqKUB4"
      },
      "source": [
        "对tensor的任何索引操作仍是一个tensor，想要获取标准的python对象数值，需要调用`tensor.item()`, 这个方法只对包含一个元素的tensor适用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8IwwF2qKUB4",
        "outputId": "fdca61f5-3d1b-490c-ad0e-3d3b6a930e07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[0,0] #依旧是tensor）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5LubRh0KUB4",
        "outputId": "fb28d996-ffe1-4b39-b1b2-016c5bde6cb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[0,0].item() # python float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOngkB8PKUB4",
        "outputId": "2fc1c700-1240-493f-bb7e-e049536d2471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 1])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = a[0:1, 0:1, None]\n",
        "print(d.shape)\n",
        "d.item() # 只包含一个元素的tensor即可调用tensor.item,与形状无关"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRhj05FyKUB5"
      },
      "outputs": [],
      "source": [
        "# a[0].item()  ->\n",
        "# raise ValueError: only one element tensors can be converted to Python scalars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXNiW1KZKUB5"
      },
      "source": [
        "#### 高级索引\n",
        "PyTorch在0.2版本中完善了索引操作，目前已经支持绝大多数numpy的高级索引[^10]。高级索引可以看成是普通索引操作的扩展，但是高级索引操作的结果一般不和原始的Tensor共享内存。 \n",
        "[^10]: https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#advanced-indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EcEVUATKUB5",
        "outputId": "4f593606-df7e-4fc7-a650-35fd9ebdb21c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8]],\n",
              "\n",
              "        [[ 9, 10, 11],\n",
              "         [12, 13, 14],\n",
              "         [15, 16, 17]],\n",
              "\n",
              "        [[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26]]])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = t.arange(0,27).view(3,3,3)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwU1NJY-KUB5",
        "outputId": "f7ab5e05-e804-4c35-e6fd-80213e007c05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([14, 24])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[[1, 2], [1, 2], [2, 0]] # x[1,1,2]和x[2,2,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysRD3jmiKUB5",
        "outputId": "cd26de8d-13f2-43d2-c947-29d695d68918"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([19, 10,  1])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[[2, 1, 0], [0], [1]] # x[2,0,1],x[1,0,1],x[0,0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARCGfYAaKUB5",
        "outputId": "9eadf8a5-379f-42cc-c640-af508fa96b50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8]],\n",
              "\n",
              "        [[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26]]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[[0, 2], ...] # x[0] 和 x[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmN8RHqkKUB6"
      },
      "source": [
        "#### Tensor类型\n",
        "\n",
        "Tensor有不同的数据类型，如表3-3所示，每种类型分别对应有CPU和GPU版本(HalfTensor除外)。默认的tensor是FloatTensor，可通过`t.set_default_tensor_type` 来修改默认tensor类型(如果默认类型为GPU tensor，则所有操作都将在GPU上进行)。Tensor的类型对分析内存占用很有帮助。例如对于一个size为(1000, 1000, 1000)的FloatTensor，它有`1000*1000*1000=10^9`个元素，每个元素占32bit/8 = 4Byte内存，所以共占大约4GB内存/显存。HalfTensor是专门为GPU版本设计的，同样的元素个数，显存占用只有FloatTensor的一半，所以可以极大缓解GPU显存不足的问题，但由于HalfTensor所能表示的数值大小和精度有限[^2]，所以可能出现溢出等问题。\n",
        "\n",
        "[^2]: https://stackoverflow.com/questions/872544/what-range-of-numbers-can-be-represented-in-a-16-32-and-64-bit-ieee-754-syste\n",
        "\n",
        "表3-3: tensor数据类型\n",
        "\n",
        "| Data type                | dtype                             | CPU tensor                                                   | GPU tensor                |\n",
        "| ------------------------ | --------------------------------- | ------------------------------------------------------------ | ------------------------- |\n",
        "| 32-bit floating point    | `torch.float32` or `torch.float`  | `torch.FloatTensor`                                          | `torch.cuda.FloatTensor`  |\n",
        "| 64-bit floating point    | `torch.float64` or `torch.double` | `torch.DoubleTensor`                                         | `torch.cuda.DoubleTensor` |\n",
        "| 16-bit floating point    | `torch.float16` or `torch.half`   | `torch.HalfTensor`                                           | `torch.cuda.HalfTensor`   |\n",
        "| 8-bit integer (unsigned) | `torch.uint8`                     | [`torch.ByteTensor`](https://pytorch.org/docs/stable/tensors.html#torch.ByteTensor) | `torch.cuda.ByteTensor`   |\n",
        "| 8-bit integer (signed)   | `torch.int8`                      | `torch.CharTensor`                                           | `torch.cuda.CharTensor`   |\n",
        "| 16-bit integer (signed)  | `torch.int16` or `torch.short`    | `torch.ShortTensor`                                          | `torch.cuda.ShortTensor`  |\n",
        "| 32-bit integer (signed)  | `torch.int32` or `torch.int`      | `torch.IntTensor`                                            | `torch.cuda.IntTensor`    |\n",
        "| 64-bit integer (signed)  | `torch.int64` or `torch.long`     | `torch.LongTensor`                                           | `torch.cuda.LongTensor`   |\n",
        "\n",
        " \n",
        "\n",
        "各数据类型之间可以互相转换，`type(new_type)`是通用的做法，同时还有`float`、`long`、`half`等快捷方法。CPU tensor与GPU tensor之间的互相转换通过`tensor.cuda`和`tensor.cpu`方法实现，此外还可以使用`tensor.to(device)`。Tensor还有一个`new`方法，用法与`t.Tensor`一样，会调用该tensor对应类型的构造函数，生成与当前tensor类型一致的tensor。`torch.*_like(tensora)` 可以生成和`tensora`拥有同样属性(类型，形状，cpu/gpu)的新tensor。 `tensor.new_*(new_shape)` 新建一个不同形状的tensor。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "fmsgq-OMKUB6"
      },
      "outputs": [],
      "source": [
        "# 设置默认tensor，注意参数是字符串\n",
        "t.set_default_tensor_type('torch.DoubleTensor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "mydKmiKYKUB6",
        "outputId": "da73eaf6-b8be-4362-b894-ff2c17664823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "a = t.Tensor(2,3)\n",
        "a.dtype # 现在a是DoubleTensor,dtype是float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "NEL94CvCKUB6"
      },
      "outputs": [],
      "source": [
        "# 恢复之前的默认设置\n",
        "t.set_default_tensor_type('torch.FloatTensor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "3EJTpsVVKUB6",
        "outputId": "4d14bd6c-f89c-44a8-8f9b-fa7b56246de5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64 torch.float32\n"
          ]
        }
      ],
      "source": [
        "# 把a转成FloatTensor，等价于b=a.type(t.FloatTensor)\n",
        "b = a.float() \n",
        "print(a.dtype, b.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "scrolled": true,
        "id": "ALPIZI_zKUB7",
        "outputId": "a5951472-fbc6-4b33-c475-d32fe0383c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "c = a.type_as(b)\n",
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "b95sS3aaKUB7",
        "outputId": "973cc028-3aec-40e8-ca95-869eaceb2127",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.6629e-310, 1.0610e-312, 1.0186e-312],\n",
              "        [9.5490e-313, 1.1034e-312, 1.0610e-312],\n",
              "        [1.2308e-312, 1.1671e-312, 1.0398e-312]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "a.new(3,3) # 等价于torch.DoubleTensor(2,3)，建议使用a.new_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkkaNug5KUB7",
        "outputId": "3524f19c-eda5-49e8-9b66-6ab20c3dbff7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.zeros_like(a) #等价于t.zeros(a.shape,dtype=a.dtype,device=a.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFfLh7YuKUB7",
        "outputId": "b1db9566-abce-4e5f-fae0-d374fbfefafd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0],\n",
              "        [0, 0, 0]], dtype=torch.int16)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.zeros_like(a, dtype=t.int16) #可以修改某些属性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fvL3wcnKUB7",
        "outputId": "2198d04c-7660-44a5-dab9-abdac7349fd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3111, 0.3843, 0.1729],\n",
              "        [0.2693, 0.6378, 0.9917]], dtype=torch.float64)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.rand_like(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er0zeaL3KUB7",
        "outputId": "d3ecd8f0-ffb0-47c2-b5e8-527d91533ea4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1]], dtype=torch.int32)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.new_ones(4,5, dtype=t.int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4EAW7z1KUB7",
        "outputId": "e3bc78e7-d939-46b4-cc9e-c9921f22eb94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 4.], dtype=torch.float64)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.new_tensor([3,4]) # "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNHnIIzaKUB8"
      },
      "source": [
        "#### 逐元素操作\n",
        "\n",
        "这部分操作会对tensor的每一个元素(point-wise，又名element-wise)进行操作，此类操作的输入与输出形状一致。常用的操作如表3-4所示。\n",
        "\n",
        "表3-4: 常见的逐元素操作\n",
        "\n",
        "|函数|功能|\n",
        "|:--:|:--:|\n",
        "|abs/sqrt/div/exp/fmod/log/pow..|绝对值/平方根/除法/指数/求余/求幂..|\n",
        "|cos/sin/asin/atan2/cosh..|相关三角函数|\n",
        "|ceil/round/floor/trunc| 上取整/四舍五入/下取整/只保留整数部分|\n",
        "|clamp(input, min, max)|超过min和max部分截断|\n",
        "|sigmod/tanh..|激活函数\n",
        "\n",
        "对于很多操作，例如div、mul、pow、fmod等，PyTorch都实现了运算符重载，所以可以直接使用运算符。如`a ** 2` 等价于`torch.pow(a,2)`, `a * 2`等价于`torch.mul(a,2)`。\n",
        "\n",
        "其中`clamp(x, min, max)`的输出满足以下公式：\n",
        "$$\n",
        "y_i =\n",
        "\\begin{cases}\n",
        "min,  & \\text{if  } x_i \\lt min \\\\\n",
        "x_i,  & \\text{if  } min \\le x_i \\le max  \\\\\n",
        "max,  & \\text{if  } x_i \\gt max\\\\\n",
        "\\end{cases}\n",
        "$$\n",
        "`clamp`常用在某些需要比较大小的地方，如取一个tensor的每个元素与另一个数的较大值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "N8vDCRp2KUB8",
        "outputId": "428879a8-e761-41e1-b3bc-890b85c057e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  0.5403, -0.4161],\n",
              "        [-0.9900, -0.6536,  0.2837]])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = t.arange(0, 6).view(2, 3).float()\n",
        "t.cos(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCUr8OzzKUB8",
        "outputId": "c2850419-aed3-4038-cb2b-824efc21b5e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [0., 1., 2.]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a % 3 # 等价于t.fmod(a, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USTH0Q2yKUB8",
        "outputId": "c3e24d4f-d59e-4701-e94d-2e2645d4e09b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  4.],\n",
              "        [ 9., 16., 25.]])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a ** 2 # 等价于t.pow(a, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGx35-TZKUB8",
        "outputId": "9b143c61-a057-4d3d-9db1-f11e028ae675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2.],\n",
            "        [3., 4., 5.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[3., 3., 3.],\n",
              "        [3., 4., 5.]])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 取a中的每一个元素与3相比较大的一个 (小于3的截断成3)\n",
        "print(a)\n",
        "t.clamp(a, min=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-weDvGjKUB8",
        "outputId": "98108fe6-5e5d-4748-93be-a3d8b9990ee4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.8415,  0.9093],\n",
              "        [ 0.1411, -0.7568, -0.9589]])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = a.sin_() # 效果同 a = a.sin();b=a ,但是更高效节省显存\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B37SfmozKUB9"
      },
      "source": [
        "####  归并操作 \n",
        "此类操作会使输出形状小于输入形状，并可以沿着某一维度进行指定操作。如加法`sum`，既可以计算整个tensor的和，也可以计算tensor中每一行或每一列的和。常用的归并操作如表3-5所示。\n",
        "\n",
        "表3-5: 常用归并操作\n",
        "\n",
        "|函数|功能|\n",
        "|:---:|:---:|\n",
        "|mean/sum/median/mode|均值/和/中位数/众数|\n",
        "|norm/dist|范数/距离|\n",
        "|std/var|标准差/方差|\n",
        "|cumsum/cumprod|累加/累乘|\n",
        "\n",
        "以上大多数函数都有一个参数**`dim`**，用来指定这些操作是在哪个维度上执行的。关于dim(对应于Numpy中的axis)的解释众说纷纭，这里提供一个简单的记忆方式：\n",
        "\n",
        "假设输入的形状是(m, n, k)\n",
        "\n",
        "- 如果指定dim=0，输出的形状就是(1, n, k)或者(n, k)\n",
        "- 如果指定dim=1，输出的形状就是(m, 1, k)或者(m, k)\n",
        "- 如果指定dim=2，输出的形状就是(m, n, 1)或者(m, n)\n",
        "\n",
        "size中是否有\"1\"，取决于参数`keepdim`，`keepdim=True`会保留维度`1`。注意，以上只是经验总结，并非所有函数都符合这种形状变化方式，如`cumsum`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7jtBZyEKUB9",
        "outputId": "b1314f55-1aae-4251-9298-fa4addf9186d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2.]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = t.ones(2, 3)\n",
        "b.sum(dim = 0, keepdim=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN9O42DTKUB9",
        "outputId": "89e10bbd-b6d4-4da1-fdaa-61d42f456043"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2., 2., 2.])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# keepdim=False，不保留维度\"1\"，注意形状\n",
        "b.sum(dim=0, keepdim=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLXmGyLgKUB9",
        "outputId": "bf7c89de-aa0b-499c-9103-bf549245b3ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 3.])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.sum(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iPP2AsfKUB9",
        "outputId": "74852992-5448-47d4-c5f7-96783372cd15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  3],\n",
              "        [ 3,  7, 12]])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = t.arange(0, 6).view(2, 3)\n",
        "print(a)\n",
        "a.cumsum(dim=1) # 沿着行累加"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1yJ7FPvKUB9"
      },
      "source": [
        "#### 比较\n",
        "比较函数中有一些是逐元素比较，操作类似于逐元素操作，还有一些则类似于归并操作。常用比较函数如表3-6所示。\n",
        "\n",
        "表3-6: 常用比较函数\n",
        "\n",
        "|函数|功能|\n",
        "|:--:|:--:|\n",
        "|gt/lt/ge/le/eq/ne|大于/小于/大于等于/小于等于/等于/不等|\n",
        "|topk|最大的k个数|\n",
        "|sort|排序|\n",
        "|max/min|比较两个tensor最大最小值|\n",
        "\n",
        "表中第一行的比较操作已经实现了运算符重载，因此可以使用`a>=b`、`a>b`、`a!=b`、`a==b`，其返回结果是一个`ByteTensor`，可用来选取元素。max/min这两个操作比较特殊，以max来说，它有以下三种使用情况：\n",
        "- t.max(tensor)：返回tensor中最大的一个数\n",
        "- t.max(tensor,dim)：指定维上最大的数，返回tensor和下标\n",
        "- t.max(tensor1, tensor2): 比较两个tensor相比较大的元素\n",
        "\n",
        "至于比较一个tensor和一个数，可以使用clamp函数。下面举例说明。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "rd3dNsr3KUB-",
        "outputId": "921297f2-621b-430b-a9a0-942e119320bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  3.,  6.],\n",
              "        [ 9., 12., 15.]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "a = t.linspace(0, 15, 6).view(2, 3)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "9mANZ1YiKUB-",
        "outputId": "99bd2895-aa69-419f-d280-86095ac07d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[15., 12.,  9.],\n",
              "        [ 6.,  3.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "b = t.linspace(15, 0, 6).view(2, 3)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZAxAsZgKUB-",
        "outputId": "3e8dea28-0319-4be2-fa57-b53660e5cdfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0],\n",
              "        [1, 1, 1]], dtype=torch.uint8)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a>b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "CbRz3cUzKUB-",
        "outputId": "232e1267-a90b-4ca5-f8b7-177c064b26ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 12., 15.])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[a>b] # a中大于b的元素"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN-a7E-PKUB-",
        "outputId": "ee0b4eb3-2429-4971-8ff1-a6e8b4cefd9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(15.)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.max(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "zcBgtv3_KUB-",
        "outputId": "adfb0936-18eb-473a-974c-4dbb77b8c783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([15.,  6.]), indices=tensor([0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "t.max(b, dim=1) \n",
        "# 第一个返回值的15和6分别表示第0行和第1行最大的元素\n",
        "# 第二个返回值的0和0表示上述最大的数是该行第0个元素"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "wWBVRps4KUB-",
        "outputId": "824f0cc0-4c90-4f33-c061-afdd2709f147"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[15., 12.,  9.],\n",
              "        [ 9., 12., 15.]])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.max(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6hXZn2IKUB_",
        "outputId": "4ae389fd-609e-404a-dd81-82414f35563b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10.],\n",
              "        [10., 12., 15.]])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 比较a和10较大的元素\n",
        "t.clamp(a, min=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-xsYGINKUB_"
      },
      "source": [
        "#### 线性代数\n",
        "\n",
        "PyTorch的线性函数主要封装了Blas和Lapack，其用法和接口都与之类似。常用的线性代数函数如表3-7所示。\n",
        "\n",
        "表3-7: 常用的线性代数函数\n",
        "\n",
        "|函数|功能|\n",
        "|:---:|:---:|\n",
        "|trace|对角线元素之和(矩阵的迹)|\n",
        "|diag|对角线元素|\n",
        "|triu/tril|矩阵的上三角/下三角，可指定偏移量|\n",
        "|mm/bmm|矩阵乘法，batch的矩阵乘法|\n",
        "|addmm/addbmm/addmv/addr/badbmm..|矩阵运算\n",
        "|t|转置|\n",
        "|dot/cross|内积/外积\n",
        "|inverse|求逆矩阵\n",
        "|svd|奇异值分解\n",
        "\n",
        "具体使用说明请参见官方文档[^3]，需要注意的是，矩阵的转置会导致存储空间不连续，需调用它的`.contiguous`方法将其转为连续。\n",
        "[^3]: http://pytorch.org/docs/torch.html#blas-and-lapack-operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Zq1tj7YPKUB_",
        "outputId": "cf672356-0cbf-433b-9bfb-7c5cec280493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "b = a.t()\n",
        "b.is_contiguous()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "w3WJlQxkKUB_",
        "outputId": "2255e3c2-afaf-404a-c146-2de3c34d1e0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  9.],\n",
              "        [ 3., 12.],\n",
              "        [ 6., 15.]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "b.contiguous()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CehWwfahKUB_"
      },
      "source": [
        "### 3.1.2 Tensor和Numpy\n",
        "\n",
        "Tensor和Numpy数组之间具有很高的相似性，彼此之间的互操作也非常简单高效。需要注意的是，Numpy和Tensor共享内存。由于Numpy历史悠久，支持丰富的操作，所以当遇到Tensor不支持的操作时，可先转成Numpy数组，处理后再转回tensor，其转换开销很小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "L7ZeImKuKUB_",
        "outputId": "a58b8668-f548-4164-d42b-bec7507ff20e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1.],\n",
              "       [1., 1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.ones([2, 3],dtype=np.float32)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "lrnA5WHSKUB_",
        "outputId": "24b16dec-081f-4f90-84d6-09cd545c0cad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "b = t.from_numpy(a)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "qeBpTqLNKUCA",
        "outputId": "6cd07753-d4c7-4d7a-cba5-6f3edd225f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "b = t.Tensor(a) # 也可以直接将numpy对象传入Tensor\n",
        "d = t.tensor(a)\n",
        "b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "scrolled": true,
        "id": "WGRjPBT6KUCA",
        "outputId": "fbc70366-7993-40bc-d219-c0f1937c32eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1., 100.,   1.],\n",
              "        [  1.,   1.,   1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "a[0, 1]=100\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "AjRT6chsKUCA",
        "outputId": "a84821c8-d73b-4903-8d94-61b79ab3e8cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  1. 100.   1.]\n",
            " [  1.   1.   1.]] tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "c = b.numpy() # a, b, c三个对象共享内存\n",
        "print(c, d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyyckNaxKUCA"
      },
      "source": [
        "**注意**： 当numpy的数据类型和Tensor的类型不一样的时候，数据会被复制，不会共享内存。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ua1cPPAAKUCA",
        "outputId": "f7d3a451-a3e2-4d8a-d656-c33b5c8b0575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "a = np.ones([2, 3])\n",
        "# 注意和上面的a的区别（dtype不是float32）\n",
        "a.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "L-lAHS_HKUCA",
        "outputId": "c0de73bd-f4f1-45fd-f683-38556f8ab6aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "b = t.Tensor(a) # 此处进行拷贝，不共享内存\n",
        "b.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "yQGzTardKUCA",
        "outputId": "6a3a9f85-dad9-47db-9096-00a525675a07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "c = t.from_numpy(a) # 注意c的类型（DoubleTensor）\n",
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "WuJE69gRKUCB",
        "outputId": "ff1f8812-8d70-4cf8-e803-2f38b3162e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "a[0, 1] = 100\n",
        "b # b与a不共享内存，所以即使a改变了，b也不变"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "x46wQtMvKUCB",
        "outputId": "fbaef364-83ed-4664-dfef-9ceb8b7be3e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1., 100.,   1.],\n",
              "        [  1.,   1.,   1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "c # c与a共享内存"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYc2EYlSKUCB"
      },
      "source": [
        "**注意：** 不论输入的类型是什么，t.tensor都会进行数据拷贝，不会共享内存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_DX8VXXKUCB"
      },
      "outputs": [],
      "source": [
        "tensor = t.tensor(a) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXVyaftrKUCB",
        "outputId": "23859d62-8a0f-4c5a-ecb4-6f4fa8d6f3c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  1., 100.,   1.],\n",
              "       [  1.,   1.,   1.]])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor[0,0]=0\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ddWPjSiKUCB"
      },
      "source": [
        "广播法则(broadcast)是科学运算中经常使用的一个技巧，它在快速执行向量化的同时不会占用额外的内存/显存。\n",
        "Numpy的广播法则定义如下：\n",
        "\n",
        "- 让所有输入数组都向其中shape最长的数组看齐，shape中不足的部分通过在前面加1补齐\n",
        "- 两个数组要么在某一个维度的长度一致，要么其中一个为1，否则不能计算 \n",
        "- 当输入数组的某个维度的长度为1时，计算时沿此维度复制扩充成一样的形状\n",
        "\n",
        "PyTorch当前已经支持了自动广播法则，但是笔者还是建议读者通过以下两个函数的组合手动实现广播法则，这样更直观，更不易出错：\n",
        "\n",
        "- `unsqueeze`或者`view`，或者tensor[None],：为数据某一维的形状补1，实现法则1\n",
        "- `expand`或者`expand_as`，重复数组，实现法则3；该操作不会复制数组，所以不会占用额外的空间。\n",
        "\n",
        "注意，repeat实现与expand相类似的功能，但是repeat会把相同数据复制多份，因此会占用额外的空间。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Dy1-xIhEKUCB"
      },
      "outputs": [],
      "source": [
        "a = t.ones(3, 2)\n",
        "b = t.zeros(2, 3,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_I4d22qbKUCB",
        "outputId": "a4ca8131-c6bf-4a70-df1e-70ed112cf831"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.]],\n",
              "\n",
              "        [[1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.]]])"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 自动广播法则\n",
        "# 第一步：a是2维,b是3维，所以先在较小的a前面补1 ，\n",
        "#               即：a.unsqueeze(0)，a的形状变成（1，3，2），b的形状是（2，3，1）,\n",
        "# 第二步:   a和b在第一维和第三维形状不一样，其中一个为1 ，\n",
        "#               可以利用广播法则扩展，两个形状都变成了（2，3，2）\n",
        "a+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4cxSSU2KUCC",
        "outputId": "0e528b09-8cdd-45c6-f541-ffeec28c16b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.]],\n",
              "\n",
              "        [[1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.]]])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 手动广播法则\n",
        "# 或者 a.view(1,3,2).expand(2,3,2)+b.expand(2,3,2)\n",
        "a[None].expand(2, 3, 2) + b.expand(2,3,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArfUkexsKUCC"
      },
      "outputs": [],
      "source": [
        "# expand不会占用额外空间，只会在需要的时候才扩充，可极大节省内存\n",
        "e = a.unsqueeze(0).expand(10000000000000, 3,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_pjIsTFKUCC"
      },
      "source": [
        "### 3.1.3 内部结构\n",
        "\n",
        "tensor的数据结构如图3-1所示。tensor分为头信息区(Tensor)和存储区(Storage)，信息区主要保存着tensor的形状（size）、步长（stride）、数据类型（type）等信息，而真正的数据则保存成连续数组。由于数据动辄成千上万，因此信息区元素占用内存较少，主要内存占用则取决于tensor中元素的数目，也即存储区的大小。\n",
        "\n",
        "一般来说一个tensor有着与之相对应的storage, storage是在data之上封装的接口，便于使用，而不同tensor的头信息一般不同，但却可能使用相同的数据。下面看两个例子。\n",
        "\n",
        "![图3-1: Tensor的数据结构](https://github.com/guanzhe9112/pytorch-book/blob/master/chapter03-tensor_and_autograd/imgs/tensor_data_structure.svg?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "ThsgB5cbKUCC",
        "outputId": "842cebbd-69d0-4ea7-bc0d-0dadd412ae6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0\n",
              " 1\n",
              " 2\n",
              " 3\n",
              " 4\n",
              " 5\n",
              "[torch.LongStorage of size 6]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "a = t.arange(0, 6)\n",
        "a.storage()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "nl5RD1yjKUCC",
        "outputId": "d7a69f35-4353-4593-b90d-061ed989bf41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0\n",
              " 1\n",
              " 2\n",
              " 3\n",
              " 4\n",
              " 5\n",
              "[torch.LongStorage of size 6]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "b = a.view(2, 3)\n",
        "b.storage()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "T1MYemtOKUCC",
        "outputId": "194a4859-39fc-4b9f-b68c-e1dab6bc89b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "# 一个对象的id值可以看作它在内存中的地址\n",
        "# storage的内存地址一样，即是同一个storage\n",
        "id(b.storage()) == id(a.storage())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "yXH8ZckiKUCD",
        "outputId": "30efeda9-4c57-46a9-efb3-cbe90de20b1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0, 100,   2],\n",
              "        [  3,   4,   5]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "# a改变，b也随之改变，因为他们共享storage\n",
        "a[1] = 100\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "cXTpU8H_KUCD",
        "outputId": "d689e001-6cc5-45d6-eedd-f370cb57d0b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0\n",
              " 100\n",
              " 2\n",
              " 3\n",
              " 4\n",
              " 5\n",
              "[torch.LongStorage of size 6]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "c = a[2:] \n",
        "c.storage()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "F4S0tM2sKUCD",
        "outputId": "0674aa97-f5ae-45b1-fe3e-d36e22361ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94377298336976, 94377298336960)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "c.data_ptr(), a.data_ptr() # data_ptr返回tensor首元素的内存地址\n",
        "# 可以看出相差8，这是因为2*4=8--相差两个元素，每个元素占4个字节(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "T7whXRwnKUCD",
        "outputId": "c62745a3-5a14-4711-d6a0-13970ed90480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0,  100, -100,    3,    4,    5])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "c[0] = -100 # c[0]的内存地址对应a[2]的内存地址\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "qOGiUp95KUCD",
        "outputId": "fe7f0b17-75ab-4f60-cfe1-e0d78119ac0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6666,  100, -100],\n",
              "        [   3,    4,    5]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "d = t.LongTensor(c.storage())\n",
        "d[0] = 6666\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "qOWfFwz8KUCD",
        "outputId": "b246f125-710f-493b-d873-b0a186fc26eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "# 下面４个tensor共享storage\n",
        "id(a.storage()) == id(b.storage()) == id(c.storage()) == id(d.storage())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "rdMaVuiiKUCD",
        "outputId": "ee3ad4b3-519f-4071-e34c-2dab6db58fcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 2, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "a.storage_offset(), c.storage_offset(), d.storage_offset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "pQ1G4Ve5KUCE",
        "outputId": "05c6cb00-3150-452f-911f-d5a53a11df3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "e = b[::2, ::2] # 隔2行/列取一个元素\n",
        "id(e.storage()) == id(a.storage())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "C7IvF-nPKUCE",
        "outputId": "3150a4b4-fa0e-4515-f9d2-4d6abe18eaaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3, 1), (6, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "b.stride(), e.stride()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "b1bNZCvxKUCE",
        "outputId": "7e7e5ba5-3dd0-476f-fdbc-aa0668432cd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "e.is_contiguous()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VbFloyEKUCE"
      },
      "source": [
        "可见绝大多数操作并不修改tensor的数据，而只是修改了tensor的头信息。这种做法更节省内存，同时提升了处理速度。在使用中需要注意。\n",
        "此外有些操作会导致tensor不连续，这时需调用`tensor.contiguous`方法将它们变成连续的数据，该方法会使数据复制一份，不再与原来的数据共享storage。\n",
        "另外读者可以思考一下，之前说过的高级索引一般不共享stroage，而普通索引共享storage，这是为什么？（提示：普通索引可以通过只修改tensor的offset，stride和size，而不修改storage来实现）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqAb5q18KUCE"
      },
      "source": [
        "### 3.1.4 其它有关Tensor的话题\n",
        "这部分的内容不好专门划分一小节，但是笔者认为仍值得读者注意，故而将其放在这一小节。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-7RwIL1KUCE"
      },
      "source": [
        "#### GPU/CPU\n",
        "tensor可以很随意的在gpu/cpu上传输。使用`tensor.cuda(device_id)`或者`tensor.cpu()`。另外一个更通用的方法是`tensor.to(device)`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "h8elDxA6KUCE",
        "outputId": "51a32ffb-f27f-412b-d68b-69b4ab8dcf5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "a = t.randn(3, 4)\n",
        "a.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "JSwI7j6VKUCE",
        "outputId": "864417ae-b713-4c7f-9ad8-43d47bdd263a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "if t.cuda.is_available():\n",
        "    a = t.randn(3,4, device=t.device('cuda:0'))\n",
        "    # 等价于\n",
        "    # a.t.randn(3,4).cuda(1)\n",
        "    # 但是前者更快\n",
        "    print(a.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7dvUpfvKUCF",
        "outputId": "3c850d50-b8c5-4b90-c1af-7d59fd68297e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.8934,  0.8776,  2.3714, -0.0861],\n",
              "        [-0.2218,  1.7379,  0.5166,  0.2940],\n",
              "        [ 1.1621,  0.6702, -0.4791, -0.7298]])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = t.device('cpu')\n",
        "a.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT0mb_MoKUCF"
      },
      "source": [
        "**注意**\n",
        "- 尽量使用`tensor.to(device)`, 将`device`设为一个可配置的参数，这样可以很轻松的使程序同时兼容GPU和CPU\n",
        "- 数据在GPU之中传输的速度要远快于内存(CPU)到显存(GPU), 所以尽量避免频繁的在内存和显存中传输数据。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-d4jUhXKUCF"
      },
      "source": [
        "#### 持久化\n",
        "Tensor的保存和加载十分的简单，使用t.save和t.load即可完成相应的功能。在save/load时可指定使用的`pickle`模块，在load时还可将GPU tensor映射到CPU或其它GPU上。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "scrolled": true,
        "id": "gmBR7KJeKUCF",
        "outputId": "7e643e90-2ca4-4a02-9e4d-8d63ba505480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 cpu cuda:0 tensor([[-1.0334, -2.4730, -0.6171,  0.7291],\n",
            "        [-1.0715,  1.0921, -1.6281, -0.7399],\n",
            "        [-1.0885,  0.4155,  0.0286, -0.5085]], device='cuda:0')\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "if t.cuda.is_available():\n",
        "    a = a.cuda(0) # 把a转为GPU1上的tensor,\n",
        "    t.save(a,'a.pth')\n",
        "\n",
        "    # 加载为b, 存储于GPU1上(因为保存时tensor就在GPU1上)\n",
        "    b = t.load('a.pth')\n",
        "    # 加载为c, 存储于CPU\n",
        "    c = t.load('a.pth', map_location=lambda storage, loc: storage)\n",
        "    # 加载为d, 存储于GPU0上\n",
        "    d = t.load('a.pth', map_location={'cuda:1':'cuda:0'})\n",
        "    print(b.device, c.device, d.device, d)\n",
        "print(t.cuda.device_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akB0vnYQKUCF"
      },
      "source": [
        "####   向量化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTuQ0lNCKUCF"
      },
      "source": [
        "向量化计算是一种特殊的并行计算方式，相对于一般程序在同一时间只执行一个操作的方式，它可在同一时间执行多个操作，通常是对不同的数据执行同样的一个或一批指令，或者说把指令应用于一个数组/向量上。向量化可极大提高科学运算的效率，Python本身是一门高级语言，使用很方便，但这也意味着很多操作很低效，尤其是`for`循环。在科学计算程序中应当极力避免使用Python原生的`for循环`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE00XoDZKUCF"
      },
      "outputs": [],
      "source": [
        "def for_loop_add(x, y):\n",
        "    result = []\n",
        "    for i,j in zip(x, y):\n",
        "        result.append(i + j)\n",
        "    return t.Tensor(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "PFxpv_mUKUCG",
        "outputId": "d0e63069-337b-4875-a3ec-a596fb332341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 997 µs per loop\n",
            "The slowest run took 5.80 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 3: 4.91 µs per loop\n"
          ]
        }
      ],
      "source": [
        "x = t.zeros(100)\n",
        "y = t.ones(100)\n",
        "%timeit -n 10 for_loop_add(x, y)\n",
        "%timeit -n 10 x + y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX5ulmPGKUCJ"
      },
      "source": [
        "可见二者有超过几十倍的速度差距，因此在实际使用中应尽量调用内建函数(buildin-function)，这些函数底层由C/C++实现，能通过执行底层优化实现高效计算。因此在平时写代码时，就应养成向量化的思维习惯，千万避免对较大的tensor进行逐元素遍历。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tQIk9eeKUCJ"
      },
      "source": [
        "此外还有以下几点需要注意：\n",
        "- 大多数`t.function`都有一个参数`out`，这时候产生的结果将保存在out指定tensor之中。\n",
        "- `t.set_num_threads`可以设置PyTorch进行CPU多线程并行计算时候所占用的线程数，这个可以用来限制PyTorch所占用的CPU数目。\n",
        "- `t.set_printoptions`可以用来设置打印tensor时的数值精度和格式。\n",
        "下面举例说明。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OneEqe4iKUCJ",
        "outputId": "06dac815-1dbb-49f0-830a-9ff205a05ff7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(199999999) tensor(199999998)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(19999999), tensor(19999998))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "a = t.arange(0, 200000000)\n",
        "print(a[-1], a[-2]) # 32bit的IntTensor精度有限导致溢出\n",
        "b = t.LongTensor()\n",
        "t.arange(0, 20000000, out=b) # 64bit的LongTensor不会溢出\n",
        "b[-1],b[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KTGFT6lZKUCJ",
        "outputId": "117933ce-815a-4233-84aa-0d50a3427641",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4622, -1.5725, -1.1932],\n",
              "        [ 0.7583,  0.5277, -0.5024]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "a = t.randn(2,3)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": false,
        "id": "7cd9EwuDKUCJ",
        "outputId": "0cc40ea6-51f4-4b4d-b22d-c702c9572a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4621572196, -1.5724859238, -1.1932091713],\n",
              "        [ 0.7583339810,  0.5276845098, -0.5024168491]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "t.set_printoptions(precision=10)\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vmWrrP1KUCJ"
      },
      "source": [
        "### 3.1.5 小试牛刀：线性回归"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vULUknJKUCK"
      },
      "source": [
        "线性回归是机器学习入门知识，应用十分广泛。线性回归利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的，其表达形式为$y = wx+b+e$，$e$为误差服从均值为0的正态分布。首先让我们来确认线性回归的损失函数：\n",
        "$$\n",
        "loss = \\sum_i^N \\frac 1 2 ({y_i-(wx_i+b)})^2\n",
        "$$\n",
        "然后利用随机梯度下降法更新参数$\\textbf{w}$和$\\textbf{b}$来最小化损失函数，最终学得$\\textbf{w}$和$\\textbf{b}$的数值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FeaeBLs5KUCK"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "device = t.device('cpu') #如果你想用gpu，改成t.device('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v3DYiX2hKUCK"
      },
      "outputs": [],
      "source": [
        "# 设置随机数种子，保证在不同电脑上运行时下面的输出一致\n",
        "t.manual_seed(1000) \n",
        "\n",
        "def get_fake_data(batch_size=8):\n",
        "    ''' 产生随机数据：y=x*2+3，加上了一些噪声'''\n",
        "    x = t.rand(batch_size, 1, device=device) * 5\n",
        "    y = x * 2 + 3 +  t.randn(batch_size, 1, device=device)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "90RVPkv5KUCK",
        "outputId": "a3789ce8-c66d-4fef-e68b-f5ef887fb9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f4b26555e10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 来看看产生的x-y分布\n",
        "x, y = get_fake_data(batch_size=16)\n",
        "plt.scatter(x.squeeze().cpu().numpy(), y.squeeze().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "scrolled": false,
        "id": "GuCCd593KUCK",
        "outputId": "b6cdbdb0-3d21-4868-a282-76081ae756d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# 随机初始化参数\n",
        "w = t.rand(1, 1).to(device)\n",
        "b = t.zeros(1, 1).to(device)\n",
        "\n",
        "lr =0.02 # 学习率\n",
        "x, y = get_fake_data(batch_size=4)\n",
        "    \n",
        "# forward：计算loss\n",
        "y_pred = x.mm(w) + b.expand_as(y) # x@W等价于x.mm(w);for python3 only\n",
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for ii in range(500):\n",
        "    x, y = get_fake_data(batch_size=4)\n",
        "    \n",
        "    # forward：计算loss\n",
        "    y_pred = x.mm(w) + b.expand_as(y) # x@W等价于x.mm(w);for python3 only\n",
        "    loss = 0.5 * (y_pred - y) ** 2 # 均方误差\n",
        "    loss = loss.mean()\n",
        "    \n",
        "    # backward：手动计算梯度\n",
        "    dloss = 1\n",
        "    dy_pred = dloss * (y_pred - y)\n",
        "    \n",
        "    dw = x.t().mm(dy_pred)\n",
        "    db = dy_pred.sum()\n",
        "    \n",
        "    # 更新参数\n",
        "    w.sub_(lr * dw)\n",
        "    b.sub_(lr * db)\n",
        "    \n",
        "    if ii%50 ==0:\n",
        "       \n",
        "        # 画图\n",
        "        display.clear_output(wait=True)\n",
        "        x = t.arange(0, 6).view(-1, 1)\n",
        "        y = x.float().mm(w) + b\n",
        "        plt.plot(x.cpu().numpy(), y.cpu().numpy()) # predicted\n",
        "        \n",
        "        x2, y2 = get_fake_data(batch_size=32) \n",
        "        plt.scatter(x2.numpy(), y2.numpy()) # true data\n",
        "        \n",
        "        plt.xlim(0, 5)\n",
        "        plt.ylim(0, 13)\n",
        "        plt.show()\n",
        "        plt.pause(0.5)\n",
        "        \n",
        "print('w: ', w.item(), 'b: ', b.item())"
      ],
      "metadata": {
        "id": "4hWZUulbesYh",
        "outputId": "be561e9a-1032-4b87-feb4-abbe8e1b378d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w:  2.1178791522979736 b:  2.9812753200531006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlycgJeNKUCK"
      },
      "source": [
        "可见程序已经基本学出w=2、b=3，并且图中直线和数据已经实现较好的拟合。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXG8yIc2KUCK"
      },
      "source": [
        ":虽然上面提到了许多操作，但是只要掌握了这个例子基本上就可以了，其他的知识，读者日后遇到的时候，可以再看看这部份的内容或者查找对应文档。\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hEz8-DCsgYjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Tensor.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}